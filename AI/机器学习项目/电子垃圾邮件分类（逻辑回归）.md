# 电子垃圾邮件分类（逻辑回归）

## 项目步骤概览

1. **数据准备**：我们可以使用公开的垃圾邮件数据集（如UCI Machine Learning Repository上的“SpamBase”数据集）。
2. **数据预处理**：包括特征提取和数据清洗。
3. **逻辑回归模型构建**：使用逻辑回归进行分类，选择合适的超参数。
4. **模型训练**：分割数据集，训练模型。
5. **模型评估**：使用指标如准确率、精确率和召回率评估模型性能。
6. **优化与调参**：进一步调整模型以提升性能。
7. **总结与展示**：展示分类结果，并总结项目中的发现。

## 代码

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# 加载数据集
url = "./spambase.data"
columns = [f"feature_{i}" for i in range(57)] + ["label"]  # 给特征和标签列命名
data = pd.read_csv(url, header=None, names=columns)

# 查看前几行
print(data.head())

# 检查是否有缺失值
print("\n缺失值统计")
print(data.isnull().sum().sum())

# 目标标签分布
print("\n目标标签分布：")
print(data['label'].value_counts())

# 分割特征与标签
X = data.drop(columns="label")
y = data["label"]

# 数据集分割
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 特征归一化
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 初始化逻辑回归模型
# 最大迭代次数：1000
log_reg_model = LogisticRegression(random_state=42, max_iter=1000)

# 训练模型
log_reg_model.fit(X_train, y_train)

# 进行预测
# 这里我们用测试集 X_test 输入到训练好的模型 log_reg_model 中，得到预测结果 y_pred，它表示模型预测的垃圾邮件与非垃圾邮件的标签（0 或 1）
y_pred = log_reg_model.predict(X_test)

# 计算评估指标
# 准确率：`accuracy_score(y_test, y_pred)` 计算模型在测试集上的整体预测准确性，也就是正确分类的比例
accuracy = accuracy_score(y_test, y_pred)
# 精确率：`precision_score(y_test, y_pred)` 计算在模型预测为垃圾邮件的邮件中，实际是垃圾邮件的比例
precision = precision_score(y_test, y_pred)
# 召回率：`recall_score(y_test, y_pred)` 计算所有实际是垃圾邮件的邮件中被正确预测为垃圾邮件的比例
recall = recall_score(y_test, y_pred)
# F1 得分：`f1_score(y_test, y_pred)` 是精确率和召回率的平衡得分，数值在 0 到 1 之间，用于综合评价模型
f1 = f1_score(y_test, y_pred)

# 输出结果
print("模型评估指标：")
print(f"准确率：{accuracy:.4f}")
print(f"精确率：{precision:.4f}")
print(f"召回率：{recall:.4f}")
print(f"F1得分：{f1:.4f}")
```

