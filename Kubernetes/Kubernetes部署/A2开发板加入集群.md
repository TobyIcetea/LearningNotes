# A2 开发板加入集群

## 1. 主机规划

规划好主机的 IP 地址。本次我们使用一个虚拟机作为 master 节点，一个虚拟机作为 worker 节点，加上一个 Atlas 200I DK A2 作为另一个 worker 节点。

整体的网段规划都在 `192.168.137.*` 网段，具体说，我们使用的三台主机的 IP 地址规划如下：

| 节点名 | IP地址          |
| ------ | --------------- |
| master | 192.168.137.101 |
| node   | 192.168.137.102 |
| atlas  | 192.168.137.100 |

## 2. 环境初始化

master 节点和 node 节点的配置在另一个文档中已经描述得比较清楚了，这里主要是考虑如何将开发板加入集群。这其中主要涉及到两方面的问题：

- 开发板是 arm64 架构的
- 一些软件需要按照 Ascend 的规范

所以下面讲的都是对开发板的配置：

1. 主机名解析。

    为了方面后续集群节点之间的直接调用：

    ```bash
    hostnamectl set-hostname atlas
    
    vim /etc/hosts
    # 加入下面的内容
    ---------------------------------------
    192.168.137.100		atlas
    192.168.137.101		master
    192.168.137.102		node
    ---------------------------------------
    ```

5. 禁用 swap 分区。

    ```bash
    # 开发板或许是做了什么特殊的设置，在 /etc/fstab 中禁用是不起作用的
    # 但是我们还是改一下，给 /etc/fstab 中所有行前面都加一个 #
    sed -i 's/^/#/' /etc/fstab
    
    swapon --show
    # 发现 swap 分区还是打开的
    
    # 将 swapoff -a 设置为开机自动执行
    sed -i '/^exit 0/i /sbin/swapoff -a' /etc/rc.local
    ```
    
6. 修改 Linux 内核参数。

    ```bash
    cat << EOF >> /etc/sysctl.d/kubernetes.conf
    net.bridge.bridge-nf-call-ip6tables = 1
    net.bridge.bridge-nf-call-iptables = 1
    net.ipv4.ip_forward = 1
    EOF
    
    # 重新加载配置
    sysctl -p
    
    # 加载网桥过滤模块
    # 将加载模块的配置写入文件中，这样可以永久生效
    echo "br_netfilter" | sudo tee /etc/modules-load.d/br_netfilter.conf && sudo modprobe br_netfilter
    
    # 查看网桥过滤模块是否加载成功
    lsmod | grep br_netfilter
    ```

4. 配置 ipvs 功能。

    ```bash
    # 安装 ipset 和 ipvsadm
    apt install ipset ipvsadm -y
    
    # 添加需要加载的模块写入配置文件
    cat << EOF > /etc/modules-load.d/ipvs.conf
    ip_vs
    ip_vs_rr
    ip_vs_wrr
    ip_vs_sh
    nf_conntrack
    EOF
    
    # 重启之后，查看对应的模块是否加载成功
    lsmod | grep -e ip_vs -e nf_conntrack
    ```

8. 重启开发板。

    ```bash
    reboot
    ```

## 3. 安装 containerd

这里我们使用了最新版的 cri-containerd-cni 包进行安装：

```bash
wget https://github.com/containerd/containerd/releases/download/v1.7.26/cri-containerd-cni-1.7.27-linux-arm64.tar.gz

tar zxvf cri-containerd-cni-1.7.27-linux-arm64.tar.gz -C /
```

之后删除默认的网络插件配置文件：

```bash
# 删除 /etc/cni/net.d 目录下的自带的文件
# 在部署 k8s 集群的时候，这个文件夹下面是不需要有文件的
# 自带的这个文件会让 pod 网络在另一个网段上
rm /etc/cni/net.d/10-containerd-net.conflist
```

生成 containerd 的配置文件：

```bash
mkdir /etc/containerd

containerd config default > /etc/containerd/config.toml
vim /etc/containerd/config.toml
---------------------------------------------------------------------------------
# 如果要配置 K8s 的话，就要修改这里
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
  SystemdCgroup = true
# 如果容器启动不起来，爆出 sandbox_image 之类的东西，可以修改这里
  sandbox_image = "registry.aliyuncs.com/google_containers/pause:3.9"
# 修改镜像加速文件地址
  config_path = "/etc/containerd/certs.d"
---------------------------------------------------------------------------------

# 加载配置、启动
systemctl daemon-reload
systemctl enable --now containerd
```

配置镜像加速地址：

```bash
# docker hub镜像加速
mkdir -p /etc/containerd/certs.d/docker.io
cat > /etc/containerd/certs.d/docker.io/hosts.toml << EOF
server = "https://docker.io"
[host."https://1ecf599359e64520bd04701e6d7184e8.mirror.swr.myhuaweicloud.com"]
  capabilities = ["pull", "resolve"]

[host."https://le2c3l3b.mirror.aliyuncs.com"]
  capabilities = ["pull", "resolve"]

[host."https://docker.m.daocloud.io"]
  capabilities = ["pull", "resolve"]

[host."https://reg-mirror.qiniu.com"]
  capabilities = ["pull", "resolve"]

[host."https://registry.docker-cn.com"]
  capabilities = ["pull", "resolve"]

[host."http://hub-mirror.c.163.com"]
  capabilities = ["pull", "resolve"]

EOF

# registry.k8s.io镜像加速
mkdir -p /etc/containerd/certs.d/registry.k8s.io
tee /etc/containerd/certs.d/registry.k8s.io/hosts.toml << 'EOF'
server = "https://registry.k8s.io"

[host."https://k8s.m.daocloud.io"]
  capabilities = ["pull", "resolve", "push"]
EOF

# docker.elastic.co镜像加速
mkdir -p /etc/containerd/certs.d/docker.elastic.co
tee /etc/containerd/certs.d/docker.elastic.co/hosts.toml << 'EOF'
server = "https://docker.elastic.co"

[host."https://elastic.m.daocloud.io"]
  capabilities = ["pull", "resolve", "push"]
EOF

# gcr.io镜像加速
mkdir -p /etc/containerd/certs.d/gcr.io
tee /etc/containerd/certs.d/gcr.io/hosts.toml << 'EOF'
server = "https://gcr.io"

[host."https://gcr.m.daocloud.io"]
  capabilities = ["pull", "resolve", "push"]
EOF

# ghcr.io镜像加速
mkdir -p /etc/containerd/certs.d/ghcr.io
tee /etc/containerd/certs.d/ghcr.io/hosts.toml << 'EOF'
server = "https://ghcr.io"
[host."https://1ecf599359e64520bd04701e6d7184e8.mirror.swr.myhuaweicloud.com"]
  capabilities = ["pull", "resolve"]
  
[host."https://ghcr.m.daocloud.io"]
  capabilities = ["pull", "resolve", "push"]
EOF

# k8s.gcr.io镜像加速
mkdir -p /etc/containerd/certs.d/k8s.gcr.io
tee /etc/containerd/certs.d/k8s.gcr.io/hosts.toml << 'EOF'
server = "https://k8s.gcr.io"

[host."https://k8s-gcr.m.daocloud.io"]
  capabilities = ["pull", "resolve", "push"]
EOF

# mcr.m.daocloud.io镜像加速
mkdir -p /etc/containerd/certs.d/mcr.microsoft.com
tee /etc/containerd/certs.d/mcr.microsoft.com/hosts.toml << 'EOF'
server = "https://mcr.microsoft.com"

[host."https://mcr.m.daocloud.io"]
  capabilities = ["pull", "resolve", "push"]
EOF

# nvcr.io镜像加速
mkdir -p /etc/containerd/certs.d/nvcr.io
tee /etc/containerd/certs.d/nvcr.io/hosts.toml << 'EOF'
server = "https://nvcr.io"

[host."https://nvcr.m.daocloud.io"]
  capabilities = ["pull", "resolve", "push"]
EOF

# quay.io镜像加速
mkdir -p /etc/containerd/certs.d/quay.io
tee /etc/containerd/certs.d/quay.io/hosts.toml << 'EOF'
server = "https://quay.io"

[host."https://quay.m.daocloud.io"]
  capabilities = ["pull", "resolve", "push"]
EOF

# registry.jujucharms.com镜像加速
mkdir -p /etc/containerd/certs.d/registry.jujucharms.com
tee /etc/containerd/certs.d/registry.jujucharms.com/hosts.toml << 'EOF'
server = "https://registry.jujucharms.com"

[host."https://jujucharms.m.daocloud.io"]
  capabilities = ["pull", "resolve", "push"]
EOF

# rocks.canonical.com镜像加速
mkdir -p /etc/containerd/certs.d/rocks.canonical.com
tee /etc/containerd/certs.d/rocks.canonical.com/hosts.toml << 'EOF'
server = "https://rocks.canonical.com"

[host."https://rocks-canonical.m.daocloud.io"]
  capabilities = ["pull", "resolve", "push"]
EOF
```

## 4. 安装 k8s 组件

```bash
# 由于 K8s 的镜像源在国外，速度比较慢，这里换成国内的镜像源
apt-get update && apt-get install -y apt-transport-https
curl -fsSL https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/deb/Release.key |
    gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/deb/ /" |
    tee /etc/apt/sources.list.d/kubernetes.list
apt-get update
apt-get install -y kubelet kubeadm kubectl

# 设置 kubelet 开机自启动
systemctl enable kubelet
```

## 5. 加入集群

在 master 节点上获取节点加入的命令：

```bash
[root@master ~]# kubeadm token create --print-join-command
kubeadm join 192.168.137.101:6443 --token dblf2u.9fd6ek5dwvz4cf38 --discovery-token-ca-cert-hash sha256:9e72ff25130bd6ca7e41dd7e40f87577456e5be771aa38ae0cc00b266ce3ddfd 
```

之后在我们的开发板上执行这个 join 的命令，就可以加入集群了。

## 6. 部署网络插件

```bash
# 下载 flannel
wget https://raw.githubusercontent.com/flannel-io/flannel/refs/heads/master/Documentation/kube-flannel.yml

# 加载 flannel
kubectl apply -f kube-flannel.yml
```

## 7. 验证

```bash
# 创建 pod 文件
cat << EOF > nginx-pod.yaml
apiVersion: v1
kind: Pod 
metadata:
  name: nginx-demo
spec:
  containers:
    - name: nginx
      image: nginx:latest
  nodeName: atlas
EOF

# 启动 pod
kubectl apply -f nginx-pod.yaml

# 等一会儿之后就可以看到 pod 跑起来了
[root@master ~]# kubectl get pods -o wide
NAME          READY   STATUS    RESTARTS      AGE   IP           NODE     NOMINATED NODE   READINESS GATES
nginx-demo    1/1     Running   0             45s   10.244.4.2   atlas    <none>           <none>

# 验证
curl 10.244.4.2
```





























